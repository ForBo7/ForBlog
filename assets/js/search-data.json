{
  
    
        "post0": {
            "title": "Bear Classifier",
            "content": ". Introduction . Below is my first attempt at creating my own model, with the help from the fastai course. This is an image classification model which can tell you whether a bear in an image is a grizzly bear, black bear, or teddy bear. . You can visit the classifier here to test it out for yourself! Note that it may take a minute or two for the site to load. . Load libraries . !pip install fastbook # No need to fret! fastai is specifically designed to be used with *. from fastbook import * from fastai import * from fastai.vision.all import * from fastai.vision.widgets import * . Download image files. . Specify the bears we wish to download. . bear_types = (&#39;grizzly&#39;, &#39;black&#39;, &#39;teddy&#39;,) path = Path(&#39;bears&#39;) . Download 200 (search_images_ddg defaults to 200 URLs) of each bear and create and assign them to a specific directory. . if not path.exists(): path.mkdir() for bear_type in bear_types: dest = (path/bear_type) dest.mkdir(exist_ok=True) urls = search_images_ddg(f&quot;{bear_type} bear&quot;) download_iamges(dest, urls=urls) . Check if our folder has the image files. . fns = get_image_files(path) fns . (#802) [Path(&#39;bears/grizzly/00000238.jpg&#39;),Path(&#39;bears/grizzly/00000047.jpg&#39;),Path(&#39;bears/grizzly/00000199.jpg&#39;),Path(&#39;bears/grizzly/00000237.jpg&#39;),Path(&#39;bears/grizzly/00000055.jpg&#39;),Path(&#39;bears/grizzly/00000000.png&#39;),Path(&#39;bears/grizzly/00000235.jpg&#39;),Path(&#39;bears/grizzly/00000159.jpg&#39;),Path(&#39;bears/grizzly/00000268.jpg&#39;),Path(&#39;bears/grizzly/00000266.jpg&#39;)...] . Check for corrupt images. . corrupt_images = verify_images(fns) corrupt_images . (#0) [] . Remove corrupt images. . corrupt_images.map(pathlib.Path.unlink) . (#0) [] . Load image files . DataBlock API . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128), ) . The blocks parameter allows us to specify the independent and dependent variables. . The get_items parameters tells fastai how to obtain our data. We use the get_image_files function to obtain our images. . The splitter parameter allows us to tell fastai how to split our data into training and validation sets. Since our data is one big set, we use the RandomSplitter class and tell it to use 20% of our data as the validation set. We specify a seed so the same split occurs each time. . The get_y parameter obtains our labels. The parent_label function simply gets the name of the folder a file is in. Since we have organized our bear images into different folders, with each folder having a different bear type, this will nicely handle our target labels. . The item_tfms parameter allows us to specify a transform to apply to our data. Since we want all our images to be of the same size, we use the Resize() class. . We now have a DataBlock object from which can load the data. . dls = bears.dataloaders(path) . Let us view a few images in the validation set. . dls.valid.show_batch(max_n=4, nrows=1) . Data Augmentation . Data augmentation refers to creating random variations of our input data so that they look different, but do not change their meaning. . Typical examples of data augmentation relating to images include rotation, flipping, perspective warping, brightness changes, and contrast changes. . Cropping . Above in the images of the validation set, we applied the Resize augmentation function. This function crops images to the size specified, which results in detail being lost. . Alternatively, we can squish/stretch images or pad them to our desired size. . Squishing/Stretching . The problem with squishing or stretching images to the same size is that th emodel will learn to &quot;see&quot; images the way they are not actually are. . bears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish)) dls = bears.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . Padding . The problem with padding images is that it adds extra wasted computation (the black pixels). . bears = bears.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;)) dls = bears.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . The best approach is to take random crops of different parts of the same image so that the neural network does not miss out on any details and can understand that an object can appear in different orientations. . Below, we have unique=True so that the same image is repeated with different variations. . bears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3)) dls = bears.dataloaders(path) dls.train.show_batch(max_n=4, nrows=1, unique=True) . fastai comes with a function that applies a variety of augmentations to images. This can allow a model to &quot;see&quot; and recognize images in a variety of scenarios. . bears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2)) dls = bears.dataloaders(path) dls.train.show_batch(max_n=8, nrows=2, unique=True) . Note that RandomResizedCrop is not being used so that differences can be seen more clearly. We are using the batch_tfms parameter to tell fastai that we want to use these transforms on a batch. . Training the mdoel . We do not have a lot of data. Only 200 images of each bear at most. Therefore, we will augment our images not only to get more data, but so that the model can recognize data in a variety of situations. . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms(), ) dls = bears.dataloaders(path) . We will now create our learner and fine-tune it. . We will be using the ResNet18 architecture (which is a convolutional neural network or CNN for short) and error rate as the metric. . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . Downloading: &#34;https://download.pytorch.org/models/resnet18-f37072fd.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth . epoch train_loss valid_loss error_rate time . 0 | 0.985666 | 0.104632 | 0.025000 | 00:20 | . epoch train_loss valid_loss error_rate time . 0 | 0.132230 | 0.073527 | 0.012500 | 00:22 | . 1 | 0.106222 | 0.054833 | 0.018750 | 00:22 | . 2 | 0.087129 | 0.058497 | 0.012500 | 00:20 | . 3 | 0.069890 | 0.058845 | 0.018750 | 00:19 | . Our model only has a 1.9% error rate! Not bad! Though it seems if I had done an extra epoch, the error rate may have gone down to 1.3%, judging by the previous epochs&#39; error rates. . Visualizing mistakes . We can visualize the mistakes the model is making by a confusion matrix. . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . 3 grizzly bears were misclassified as black bears. . Let us see where the errors are occurring, so we can determine if they are due to a dataset problem or a model problem. . To do this, we will sort images by their loss. . interp.plot_top_losses(5, nrows=1) . Data cleaning . The intuitive approach to data cleaning is to do it before training the model. However, a trained model can also help us clean the data. For example, we could see some mislabaled bears in the above cases. . fastai includes a GUI that allows you to choose a category/label and their associated training and validation sets and view the highest-loss images in order so that you can select images for removal or relabeling. . cleaner = ImageClassifierCleaner(learn) cleaner . ImageClassifierCleaner does not actually delete or relabel. It just returns the indices that are to be deleted or relabeled. . for index in cleaner.delete(): cleaner.fns[index].unlink() # Relabel images selected for relabeling. for index, category in cleaner.change(): shutil.move(str(cleaner.fns[index]), path/category) . We can now retrain and a better performance should be expected. . Saving the model . A model consists of two parts: the architecture and the parameters. . When we use the export() method, both of these are saved. . This method also saves the definition of your DataLoaders. This is done so that you do not have to redefine how to transform your data to use your model in production. . fastai uses your validation set DataLoader by default, so the data augmentation will not be applied, which is generally what you want. . The export() method creates a file named &quot;export.pkl&quot;. . learn.export() . Let us check that the file exists. . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . If you wish to deploy an app, this is the file you will need. . Loading the model for inference . Now obviously we do not need to load the model as we already have the learner variable. However, I will do so here for the sake of practice lol. . learn_inf = load_learner(path/&#39;export.pkl&#39;) . We generally do inference for a single image at a time. . learn_inf.predict(&#39;images/grizzly.jpg&#39;) . (&#39;grizzly&#39;, TensorBase(1), TensorBase([1.4230e-06, 1.0000e+00, 3.9502e-08])) . Three things have been returned: the predicted category, the index of the predicted category, and the probabilities of each category. . The order of each category is based of the order of the vocab of the DataLoaders; that is, the stored tuple of all possible categories. . The DataLoaders can be accessed as an attribute of the Learner. . learn_inf.dls.vocab . [&#39;black&#39;, &#39;grizzly&#39;, &#39;teddy&#39;] . A word about CNNs . Since the ResNet18 architecture is a sort of CNN, I will explain why CNNs work so well for images. I do not have a full understanding, but this is what I understand so far. . Essentially, each neuron in a layer is given the exact same weights and all neurons are input different data. This is so that all neurons fire upon detecting the same patterns. . By all neurons, in a layer, being given the exact same weights, it allows those neurons to all be triggered by the same pattern. This is why CNNs are really good at detecting objects in various patterns, orientations, shapes, positions, and so on. . Conclusion . Well then, that wraps up my first deep learning model! I have to say, it is much easier than I thought to implement a model. You do not need to go into the nitty gritty details in artificial intelligence to be able to implement them. A high level understanding will suffice. It is like playing a sport: you do not need to understand the physics to be able to play it. . Right now I am creating my own classifier that will classify cars into their company types. . If you have any comments, suggestions, or corrections, please do let me know down in the comment section below! .",
            "url": "https://forbo7.github.io/ForBlog/fastai/image%20classification/cnn/2022/05/28/bear_classifier_model.html",
            "relUrl": "/fastai/image%20classification/cnn/2022/05/28/bear_classifier_model.html",
            "date": " • May 28, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "How to Approach Creating AI Models",
            "content": ". Introduction . How you approach making your model is crucial. Articial Intelligence is not about creating models; it is only a tiny part of it. It is 80% problem solving and 20% implementing (I would not be suprised if it actually followed the 80-20 rule1). . It is like the scientific method in a sense. Sure, you can create a really accurate, well functioning experiment. But what use is it if you do not approach conducting the experiment and analyzing the results in a well defined manner? . One highly successful approach is the Drivetrain Approach, created by fast.ai course creater Jeremy Howard along with his collegues Margit Zwemer and Mike Loukides. Their official blogpost on this approach goes into much detail and can be read in full here. The goal of this approach is to not use data just to generate more data (that is in the form of predictions), but to use data to also generate actionable outcomes. . Over here, I’ll be providing a short overview of my understanding of this approach (from the fast.ai course) and will be applying it to the final project I did in the University of Helsinki’s and Reaktor’s Elements of AI course (I highly highly recommend this course; it gives a really good primer into AI). . Overview of the Drivetrain Approach . There are four main steps to this process: . Define the objective | Consider your possible actions | Consider your data | Create the models | . Define the objective . Write out what you are really trying to achieve. What is your goal? . Consider your actions . Think about what actions you can take to achieve your objective. . Also think about what would happen if you did those actions. What would happen if did x? Would y really be a good idea? What if z worked really well? What if z worked really bad? . Consider your data . Think about the data you already have and how it can be used. Think about any further data that is needed and how it could be collected. . Create the model . Created models that produce the best actions that in turn produce the best results in terms of your objective. . Endangered Language Chatbot . The final project of the Elements of AI course asked me to come up with my own AI method that would solve a problem, and how it would. I ended up creating an overview for how a chatbot could be created to preserve endangered languages. . Now that I think of it, what the project asked me to do is one sort of approach to creating AI methods, though more on the why side. You can view my project overview here. . Define the objective . The objective of creating such a chatbot is to preserve languages that are endangered or extinct. This would help preserve different histories and cultures, as well as humanity’s diversity. . Consider your actions . Probably, a new sort of NLP architecture would have to be created primarily due to the lack of data there would be for these languages. . Alternatively, existing methods could be applied, but there would be varying degrees of success depending on how much data is available for a language. . Consider your data . The main source of data for training such models would corpuses of text. However, this itself is a problem since many endangered or extinct languages do not have enough written text that would achieve the level of performance required to have somewhat of a good conversation with the bot. Further troubles arise for those languages that are speech only; you would need to have audio recordings, which would be extremely difficult for a language that is endangered or nigh impossible for those that are extinct. . The main solution to these problems that comes to mind is literal manpower and brute force. That is, humans would have to manually create masses of text or speech that the model can then be trained on to “learn” the langauge. . Create the model . Create a model that speaks as accurately as a native of the endangered language so that any person interacting with the chatbot gets a vivid idea of the language, its culture, and its people. . Conclusion . This concludes my understanding and explanation of one such approach to creating models, along with an attempted example. Approaches are crucial: you can have all the best tools and the most accurate models in the world, but they are worthless if not correctly approached, used, and applied. . If you have any comments, suggestions, or corrections, please do post them down in the comment section below! . Footnotes . The 80/20 Rule, also known as the Pareto Principle &#8617; . |",
            "url": "https://forbo7.github.io/ForBlog/model%20deployment/drivetrain%20approach/2022/05/27/How-to-Approach-Creating-AI-Models.html",
            "relUrl": "/model%20deployment/drivetrain%20approach/2022/05/27/How-to-Approach-Creating-AI-Models.html",
            "date": " • May 27, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Mandarin: People and Family",
            "content": ". Nǐ shì rén ma? . And so I have completed Lesson 2 of Living Language’s Essential Chinese: People and Family. In this lesson, I learned about how certain people are referred to as well as certain grammatical insights. . I have to say, this chapter was particularly interesting because I saw how the Chinese think, in terms of language. I have studied English Language in high school, including how the language developed over the centuries, how children pick up langauge, how English has spread globally, and language and the self. . Observations . Male and Female . Indicating if a person is male or female is generally straightforward: you prefix nǔ (female) or nán (male) — yes, yes, this probably does not cover all cases. . For example, person in Mandarin is rén. Therefore, woman is nǔrén (female person) and man is nánrén (male person). . Boy is nánhái and girl is nǔhái. I infer that hái must mean something in the bout of a child. . There is also no verbal difference when referring to a male or female. He/him/she/her is all spoken using the same term: tā. However, there is a written difference. He/him is 他 and she/her is 她. . The Chinese then perhaps do not make a distinction between males and females, and perhaps rather let the context of the situation speak for itself. . Conjugates and Articles . Simply put, conjugates are terms such as “to be”, “is”, “are”, “was”, and “will be”. In Chinese, there is none of that nonsense. You use a single term for every thing, person, and all times including past, present, and future. That term is shì (是). . Articles are terms such as “a”, “an”, and “the”. Similarly, Chinese has none of that nonsense and uses no such terms. . The Chinese then probably do not have strict concepts of time, as is seen by the use of shì for past, present, and future. They perhaps think of time as one continuous flow. This is also seen by the term yǒu, which is used for have had, to have, and will have. . Plurals . To make any pronoun plural, you simply append -men (们) to the end. . nǐ (你）—&gt; nǐmen (你们) | wǒ (我) —&gt; wǒmen (我们) | tā (他) —&gt; tāmen (他们) | . I have noticed that there is perhaps no distinction between plural and singular nouns. Take the below sentences as an example. Xuésheng means student. . They are a student. (Tāmen shì xuésheng.) . They are our students. (Tāmen shì wǒmen xuésheng.) . Xuésheng is used for both student and students. . Family . The terms used to refer to siblings are very easy to pronounce. Perhaps so that young children can easily speak them, as is seen below: . younger brother: dìdi | older brother: gēge | younger sister: mèimei | older sister: jiějie | . More Strokes . Tí . As it sounds, goes from bottom left to top right. . ㇀ . It can be longer or shorter than what is shown above and can also be more horizontal/shallow too. . Shùgōu . It is a shù with with a gōu. . 亅 . Wāngōu . It is a shùgōu with an initial curve. . ㇁ . Shùtí1 . It is a shù with a tí. . . Xiégōu . It is like a curved shùtí. . ㇂ . Nà . It is like a mirrored piě. . ㇏ . It can be more horizontal or vertical than what is shown above. . Hanzì Characters . Hanzì characters can never contain more than one nà stroke. . Conclusion . That concludes my observation for Lesson 2. If you have any comments, suggestions, or corrections, please do put them down in the comments section below! . Next up is Lesson 3: Numbers! Wǒ yǒu yī gè dìdi. . Acknowledements . Shùtí stroke image: CJK stroke by Canjie6 / CC BY 4.0 &#8617; . |",
            "url": "https://forbo7.github.io/ForBlog/mandarin/hanz%C3%AC/2022/05/26/Mandarin-People-and-Family.html",
            "relUrl": "/mandarin/hanz%C3%AC/2022/05/26/Mandarin-People-and-Family.html",
            "date": " • May 26, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Nǐ hǎo!",
            "content": ". Nǐ hǎo ma? . A fitting title for my first blog post! . So begins my venture into learning Mandarin! I am actually excited to begin learning a new language, partly because I also had a full physical course laying about. . The course in question is Living Language Chinese Complete Edition. It comes with four books (essential, intermediate, advanced, and a character guide) along with six audio CDs. Reviews for the Chinese course from Living Language seemed good too, though people tended to praise the older version more which is the one I have (I think). . . Let’s move on to what I have observed so far in learning this language, from Lesson 1 of the course. . Observations . Greetings . Nǐ hǎo. | Nǐ hǎo ma? | Nǐ ne? | . Nǐ must refer to the other person (you). . Wǒ hěn hǎo. | hěn hǎo | . Hǎo must refer to the good state [of someone]. . Tones . There are five tones in Mandarin. You can tell how to pronounce each tone by simply looking at its shape. . First tone . ā . A flat, high pitched tone. . Second tone . á . A rising tone, from medium to high pitch. . Third tone . ǎ . A scooping tone, from low to medium pitch. . Fourth tone . à . A falling tone, similar to when you say “yes” or “no” in response to a question, or when you saying something you really mean. . Fifth tone . a . A neutral, medium pitched tone. . Asking for help . Qǐng ràng yī xià? | Dǎrǎo yī xià? | Qǐngwèn yī xià? | . “yī xià” is probably used for those questions where you ask somebody for a favor or for an action from them. . “ma”, on the other hand, is probably used to turn a phrase into a question. . Hanzì strokes . Observations from Character Guide book, Lesson 1 — Basic Strokes. . Héng . As it sounds, is a horizontal line from left to right. . 一 . Shù . As it sounds, is a vertical line from top to bottom. . 丨 . Piě . Is like a curved shù that can be shallow or deep. The deep variant is shown below. . 丿 . Diǎn . Is sort of like a diagonal dot. Can be drawn from top left to bottom right or top right to bottom left. Essentially can only be drawn starting from the top. . 丶 . Zhé . Is like héng, but has a hook at the end. . 乛 . “hook” in pīnyīn is gōu. Therefore, zhé is also known as hénggōu. . Hanzì Characters . I have noticed that a single hanzì character corresponds to a single syllable. . Conclusion . Well then, that concludes my initial observation and things learned in Mandarin. I’ll be making more of these sorts of posts as I continue my learning journey. . I would appreciate any comments, corrections, and suggesstions! .",
            "url": "https://forbo7.github.io/ForBlog/mandarin/hanz%C3%AC/2022/05/21/N%C7%90-h%C7%8Eo.html",
            "relUrl": "/mandarin/hanz%C3%AC/2022/05/21/N%C7%90-h%C7%8Eo.html",
            "date": " • May 21, 2022"
        }
        
    
  
    
  

  
  

  
      ,"page1": {
          "title": "Check out my Artstation!",
          "content": "Check out my ArtStation where I upload my projects and works relating to 3D computer graphics. .",
          "url": "https://forbo7.github.io/ForBlog/Artstation.html",
          "relUrl": "/Artstation.html",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Checkout my GitHub!",
          "content": "Check out my GitHub where you can see various coding projects that I have dabbled including game development and my ventures into AI. .",
          "url": "https://forbo7.github.io/ForBlog/GitHub.html",
          "relUrl": "/GitHub.html",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "About Me",
          "content": "I’m ForBo7: an approachable, adaptable, open-minded, curious individual who’s been to seventeen countries and lived in three. I’m a science and technology geek, space nerd, and currently dabble in AI. 3D computer graphics is my hobby and learning is my passion. .",
          "url": "https://forbo7.github.io/ForBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://forbo7.github.io/ForBlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}